{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bd9e671",
   "metadata": {},
   "source": [
    "# Fill Missing Frames for 'not detect' Gaps in Trajectory Data\n",
    "\n",
    "This notebook provides a template for filling missing frame data in your vehicle trajectory datasets.  \n",
    "It was designed to work with the missing frames information contained in `missing_frames_detail.csv` and multiple trajectory files (in CSV/XLSX format) that have been split into parts due to their large size.  \n",
    "\n",
    "The goal is to fill in gaps where the `missing reasons` column is **`not detect`** and return a completed trajectory dataset for each split file.\n",
    "\n",
    "**Key features of the notebook:**\n",
    "\n",
    "- **Configuration section**: specify the path to the `missing_frames_detail.csv` file and list the trajectory files you wish to process.  \n",
    "- **Gap filtering**: load missing gap information and filter to only those gaps where the `missing reasons` column is `'not detect'`.  \n",
    "- **Interpolation logic**: for each missing gap, find the nearest existing frames for the same vehicle before and after the gap, and linearly interpolate numeric fields (e.g. `x`, `y`, `w`, `h`, `s_m`, `vehicle_length`, `vehicle_width`) across missing frames.  \n",
    "  - Discrete/categorical fields (e.g. `class_id`, `vehicle_id`, `lane_observed`, `lane_smoothed`) are copied from the preceding frame when available.  \n",
    "  - `confidence` is set to `0.0` for all filled rows.  \n",
    "  - `is_lane_change` is set to `0` in filled sections to avoid falsely introducing lane changes.  \n",
    "- **Time calculations**: compute `time_s` as `frame_id / FPS` and derive `time_min_sec` via Python's `timedelta` formatting.  \n",
    "- **Audit columns**: optional columns (e.g. `fill_flag`, `fill_method`, `fill_lane_conflict`) can be added to mark rows that were created during filling.  \n",
    "- **Output**: write the filled dataset for each input file as both CSV and XLSX files, preserving the original column order.  \n",
    "\n",
    "> **Important:**\n",
    ">\n",
    "> - **Performance considerations**: because trajectory data can be extremely large, this template reads each file one at a time and operates on that subset.  \n",
    "> - You may need to adapt the interpolation logic to fit your specific schema; double-check your column names and the meaning of each field.  \n",
    "> - The paths in the configuration section are placeholders; update them to match your local environment before running the notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52a4ae12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T11:36:29.332939Z",
     "start_time": "2025-10-04T11:36:29.326472Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "\n",
    "# Path to missing frames detail CSV (update as needed)\n",
    "MISSING_FRAMES_PATH = '/Users/wss/Desktop/CSV/DJI_0031/step1 single ane and multi lanes analysis_v2_5/missing_frames_detail.csv'\n",
    "\n",
    "# List of trajectory files to process (update to your local file paths)\n",
    "TRAJ_FILES = [\n",
    "    r'/Users/wss/Desktop/CSV/DJI_0031/step1 single ane and multi lanes analysis_v2_5/combined_trajectories_part1.xlsx',\n",
    "    r'/Users/wss/Desktop/CSV/DJI_0031/step1 single ane and multi lanes analysis_v2_5/combined_trajectories_part2.xlsx',\n",
    "    r'/Users/wss/Desktop/CSV/DJI_0031/step1 single ane and multi lanes analysis_v2_5/combined_trajectories_part3.xlsx',\n",
    "    r'/Users/wss/Desktop/CSV/DJI_0031/step1 single ane and multi lanes analysis_v2_5/combined_trajectories_part4.xlsx',\n",
    "]\n",
    "\n",
    "# Frames per second of the video\n",
    "FPS = 59.94\n",
    "\n",
    "# Pixel to metre conversion factor (1 pixel = 0.102 m)\n",
    "PIXEL_TO_METRE = 0.102\n",
    "\n",
    "# Output directory for filled files\n",
    "OUTPUT_DIR = 'filled_outputs'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0201db67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T11:36:31.255652Z",
     "start_time": "2025-10-04T11:36:31.248745Z"
    }
   },
   "outputs": [],
   "source": [
    "def format_time_min_sec(seconds: float) -> str:\n",
    "    '''Convert seconds to a HH:MM:SS string.'''\n",
    "    td = timedelta(seconds=seconds)\n",
    "    total_seconds = int(td.total_seconds())\n",
    "    hours = total_seconds // 3600\n",
    "    minutes = (total_seconds % 3600) // 60\n",
    "    secs = total_seconds % 60\n",
    "    return f\"{hours:02d}:{minutes:02d}:{secs:02d}\"\n",
    "\n",
    "\n",
    "def interpolate_numeric(start_val, end_val, start_frame, end_frame, target_frame):\n",
    "    '''Linearly interpolate a value between two frames.\n",
    "    If one boundary is missing, return the available boundary value.'''\n",
    "    if start_val is None:\n",
    "        return end_val\n",
    "    if end_val is None:\n",
    "        return start_val\n",
    "    if start_frame == end_frame:\n",
    "        return start_val\n",
    "    fraction = (target_frame - start_frame) / (end_frame - start_frame)\n",
    "    return start_val + fraction * (end_val - start_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47a91133",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T11:36:32.470566Z",
     "start_time": "2025-10-04T11:36:32.448922Z"
    }
   },
   "outputs": [],
   "source": [
    "def fill_missing_gaps(df: pd.DataFrame, missing_info: pd.DataFrame, fps: float = FPS) -> pd.DataFrame:\n",
    "    '''Fill missing frames for a single trajectory DataFrame based on gap information.'''\n",
    "    output_df = df.copy()\n",
    "\n",
    "    # Identify numeric columns that may need interpolation\n",
    "    numeric_cols = ['x', 'y', 'w', 'h', 'vehicle_length', 'vehicle_width', 'x_m', 'y_m', 's_m']\n",
    "    numeric_cols = [col for col in numeric_cols if col in output_df.columns]\n",
    "\n",
    "    # Identify categorical columns to propagate\n",
    "    categorical_cols = [col for col in ['class_id', 'vehicle_id', 'lane_observed', 'lane_smoothed',\n",
    "                                        'lane_change_from', 'lane_change_to', 'combine veh uids'] if col in output_df.columns]\n",
    "\n",
    "    for _, gap in missing_info.iterrows():\n",
    "        veh_uid = gap['vehicle_uid']\n",
    "        start_frame = int(gap['gap_start_frame'])\n",
    "        end_frame = int(gap['gap_end_frame'])\n",
    "\n",
    "        veh_df = output_df[output_df['vehicle_uid'] == veh_uid]\n",
    "        if veh_df.empty:\n",
    "            continue\n",
    "\n",
    "        prev_row = veh_df[veh_df['frame_id'] < start_frame].sort_values('frame_id').tail(1)\n",
    "        next_row = veh_df[veh_df['frame_id'] > end_frame].sort_values('frame_id').head(1)\n",
    "        if prev_row.empty and next_row.empty:\n",
    "            continue\n",
    "\n",
    "        prev_frame = prev_row['frame_id'].iloc[0] if not prev_row.empty else None\n",
    "        next_frame = next_row['frame_id'].iloc[0] if not next_row.empty else None\n",
    "        prev_vals = prev_row.iloc[0] if not prev_row.empty else None\n",
    "        next_vals = next_row.iloc[0] if not next_row.empty else None\n",
    "\n",
    "        new_rows = []\n",
    "        for frame in range(start_frame, end_frame + 1):\n",
    "            if ((output_df['vehicle_uid'] == veh_uid) & (output_df['frame_id'] == frame)).any():\n",
    "                continue\n",
    "            row_dict = {\n",
    "                'frame_id': frame,\n",
    "                'vehicle_uid': veh_uid\n",
    "            }\n",
    "            # interpolate numeric fields\n",
    "            for col in numeric_cols:\n",
    "                prev_val = prev_vals[col] if prev_vals is not None and col in prev_vals else None\n",
    "                next_val = next_vals[col] if next_vals is not None and col in next_vals else None\n",
    "                row_dict[col] = interpolate_numeric(prev_val, next_val, prev_frame, next_frame, frame)\n",
    "            # convert to metres if x,y exist\n",
    "            if 'x_m' in numeric_cols and 'x' in output_df.columns:\n",
    "                row_dict['x_m'] = row_dict['x'] * PIXEL_TO_METRE\n",
    "            if 'y_m' in numeric_cols and 'y' in output_df.columns:\n",
    "                row_dict['y_m'] = row_dict['y'] * PIXEL_TO_METRE\n",
    "            # propagate categorical fields\n",
    "            for col in categorical_cols:\n",
    "                if prev_vals is not None and col in prev_vals:\n",
    "                    row_dict[col] = prev_vals[col]\n",
    "                elif next_vals is not None and col in next_vals:\n",
    "                    row_dict[col] = next_vals[col]\n",
    "            # set confidence and lane change flags\n",
    "            if 'confidence' in output_df.columns:\n",
    "                row_dict['confidence'] = 0.0\n",
    "            if 'is_lane_change' in output_df.columns:\n",
    "                row_dict['is_lane_change'] = 0\n",
    "            # compute time\n",
    "            if 'time_s' in output_df.columns:\n",
    "                row_dict['time_s'] = frame / fps\n",
    "            if 'time_min_sec' in output_df.columns:\n",
    "                row_dict['time_min_sec'] = format_time_min_sec(row_dict['time_s'])\n",
    "            new_rows.append(row_dict)\n",
    "        if new_rows:\n",
    "            new_df = pd.DataFrame(new_rows)\n",
    "            output_df = pd.concat([output_df, new_df], ignore_index=True)\n",
    "    output_df = output_df.sort_values(['vehicle_uid', 'frame_id']).reset_index(drop=True)\n",
    "    return output_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e64930c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-04T11:54:35.936390Z",
     "start_time": "2025-10-04T11:36:34.014662Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/wss/Desktop/CSV/DJI_0031/step1 single ane and multi lanes analysis_v2_5/combined_trajectories_part1.xlsx\n",
      "Processing /Users/wss/Desktop/CSV/DJI_0031/step1 single ane and multi lanes analysis_v2_5/combined_trajectories_part2.xlsx\n",
      "Processing /Users/wss/Desktop/CSV/DJI_0031/step1 single ane and multi lanes analysis_v2_5/combined_trajectories_part3.xlsx\n",
      "Processing /Users/wss/Desktop/CSV/DJI_0031/step1 single ane and multi lanes analysis_v2_5/combined_trajectories_part4.xlsx\n",
      "Filling completed. Summary:\n",
      "                                                file  original_rows  \\\n",
      "0  /Users/wss/Desktop/CSV/DJI_0031/step1 single a...         262143   \n",
      "1  /Users/wss/Desktop/CSV/DJI_0031/step1 single a...         262143   \n",
      "2  /Users/wss/Desktop/CSV/DJI_0031/step1 single a...         262053   \n",
      "3  /Users/wss/Desktop/CSV/DJI_0031/step1 single a...         253935   \n",
      "\n",
      "   filled_rows  rows_added  \n",
      "0       265732        3589  \n",
      "1       265763        3620  \n",
      "2       265699        3646  \n",
      "3       258278        4343  \n"
     ]
    }
   ],
   "source": [
    "# Load missing frames detail and filter to 'not detect' reasons\n",
    "missing_df = pd.read_csv(MISSING_FRAMES_PATH)\n",
    "not_detect_gaps = missing_df[missing_df['missing reasons'].str.lower() == 'not detect']\n",
    "\n",
    "# Prepare log\n",
    "log_entries = []\n",
    "\n",
    "for file_path in TRAJ_FILES:\n",
    "    print(f\"Processing {file_path}\")\n",
    "    # load data\n",
    "    if file_path.lower().endswith('.csv'):\n",
    "        df = pd.read_csv(file_path)\n",
    "    elif file_path.lower().endswith(('.xls', '.xlsx')):\n",
    "        df = pd.read_excel(file_path)\n",
    "    else:\n",
    "        print(f\"Unsupported file type: {file_path}\")\n",
    "        continue\n",
    "    original_count = len(df)\n",
    "    # fill gaps\n",
    "    filled_df = fill_missing_gaps(df, not_detect_gaps)\n",
    "    filled_count = len(filled_df)\n",
    "    rows_added = filled_count - original_count\n",
    "    # output file names\n",
    "    base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    csv_out = os.path.join(OUTPUT_DIR, f\"{base_name}_filled.csv\")\n",
    "    xlsx_out = os.path.join(OUTPUT_DIR, f\"{base_name}_filled.xlsx\")\n",
    "    # save\n",
    "    filled_df.to_csv(csv_out, index=False)\n",
    "    filled_df.to_excel(xlsx_out, index=False)\n",
    "    # log entry\n",
    "    log_entries.append({\n",
    "        'file': file_path,\n",
    "        'original_rows': original_count,\n",
    "        'filled_rows': filled_count,\n",
    "        'rows_added': rows_added\n",
    "    })\n",
    "\n",
    "# Save log summary\n",
    "log_df = pd.DataFrame(log_entries)\n",
    "log_path = os.path.join(OUTPUT_DIR, 'filling_summary.csv')\n",
    "log_df.to_csv(log_path, index=False)\n",
    "print(\"Filling completed. Summary:\")\n",
    "print(log_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84947068",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
