{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51db8761",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-18T11:06:57.785973Z",
     "start_time": "2025-10-18T10:49:34.737235Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Found 6 files to process.\n",
      "[1/6] Processing: /Volumes/weishanshan/Geo trax tool results/DJI_0031/step4 Splited car following behavior/lane-1_following_parts.xlsx\n",
      "[2/6] Processing: /Volumes/weishanshan/Geo trax tool results/DJI_0031/step4 Splited car following behavior/lane-2_following_parts.xlsx\n",
      "[3/6] Processing: /Volumes/weishanshan/Geo trax tool results/DJI_0031/step4 Splited car following behavior/lane1_following_parts.xlsx\n",
      "[4/6] Processing: /Volumes/weishanshan/Geo trax tool results/DJI_0031/step4 Splited car following behavior/lane2_following_parts.xlsx\n",
      "[5/6] Processing: /Volumes/weishanshan/Geo trax tool results/DJI_0031/step4 Splited car following behavior/lane_middle_LTR_following_parts.xlsx\n",
      "[6/6] Processing: /Volumes/weishanshan/Geo trax tool results/DJI_0031/step4 Splited car following behavior/lane_middle_RTL_following_parts.xlsx\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import gc\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')  # headless backend\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Tuple, Iterable\n",
    "\n",
    "# ========================= Lane inference =========================\n",
    "def infer_lane_name(file_path: str, df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Try to infer lane name like 'lane2', 'lane-1' from file path or df columns.\n",
    "    Priority:\n",
    "      1) regex from file name / path: (lane-?\\d+), case-insensitive\n",
    "      2) df column 'lane' or 'lane_smoothed' or 'lane_name' (use mode)\n",
    "      3) fallback: 'lane'\n",
    "    \"\"\"\n",
    "    basename = os.path.basename(file_path)\n",
    "    m = re.search(r'(lane-?\\d+)', basename, flags=re.IGNORECASE)\n",
    "    if not m:\n",
    "        m = re.search(r'(lane-?\\d+)', file_path, flags=re.IGNORECASE)\n",
    "    if m:\n",
    "        return m.group(1).lower()\n",
    "\n",
    "    for col in ['lane', 'lane_smoothed', 'lane_name']:\n",
    "        if col in df.columns:\n",
    "            try:\n",
    "                val = df[col].mode().iloc[0]\n",
    "                return str(val).lower()\n",
    "            except Exception:\n",
    "                pass\n",
    "    return 'lane'\n",
    "\n",
    "# ========================= Core helpers =========================\n",
    "def find_valid_segments(group: pd.DataFrame,\n",
    "                        speed_threshold: float = 3.6,   # km/h\n",
    "                        distance_threshold: float = 100.0,\n",
    "                        min_duration: float = 1.0) -> List[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Contiguous (frame_id +1), follower_v>threshold (km/h), headway<=threshold, duration>=min_duration (s)\n",
    "    \"\"\"\n",
    "    segments: List[pd.DataFrame] = []\n",
    "    current_segment_rows: List[int] = []\n",
    "    prev_frame_id = None\n",
    "\n",
    "    for idx, row in group.iterrows():\n",
    "        cond_speed = row['follower_v'] > speed_threshold\n",
    "        cond_dist = row['headway_distance_m'] <= distance_threshold\n",
    "        cond = cond_speed and cond_dist\n",
    "        if cond and (prev_frame_id is None or row['frame_id'] == prev_frame_id + 1):\n",
    "            current_segment_rows.append(idx)\n",
    "        else:\n",
    "            if current_segment_rows:\n",
    "                seg = group.loc[current_segment_rows]\n",
    "                duration = seg['time_s'].iloc[-1] - seg['time_s'].iloc[0]\n",
    "                if duration >= min_duration:\n",
    "                    segments.append(seg.copy())\n",
    "                current_segment_rows = []\n",
    "            if cond:\n",
    "                current_segment_rows.append(idx)\n",
    "        prev_frame_id = row['frame_id']\n",
    "\n",
    "    if current_segment_rows:\n",
    "        seg = group.loc[current_segment_rows]\n",
    "        duration = seg['time_s'].iloc[-1] - seg['time_s'].iloc[0]\n",
    "        if duration >= min_duration:\n",
    "            segments.append(seg.copy())\n",
    "    return segments\n",
    "\n",
    "def compute_segment_statistics(segment: pd.DataFrame) -> dict:\n",
    "    metrics = {\n",
    "        'headway_distance_m': segment['headway_distance_m'],\n",
    "        'net_headway_distance_m': segment['net_headway_distance_m'],\n",
    "        'time_headway_s': segment['time_headway_s'],\n",
    "        'net_time_headway_s': segment['net_time_headway_s'],\n",
    "        'rel_v_kph': segment['rel_v_kph'],            # km/h\n",
    "        'rel_a_mps2': segment['rel_a_mps2'],          # m/s^2\n",
    "        'TTC_s': segment['TTC_s'],                    # s\n",
    "        'leader_v': segment['leader_v'],              # km/h\n",
    "        'leader_a': segment['leader_a'],              # m/s^2\n",
    "        'follower_v': segment['follower_v'],          # km/h\n",
    "        'follower_a': segment['follower_a'],          # m/s^2\n",
    "    }\n",
    "    out = {}\n",
    "    for name, series in metrics.items():\n",
    "        clean = series.dropna()\n",
    "        out[f'{name}_min']  = clean.min()  if not clean.empty else np.nan\n",
    "        out[f'{name}_max']  = clean.max()  if not clean.empty else np.nan\n",
    "        out[f'{name}_mean'] = clean.mean() if not clean.empty else np.nan\n",
    "    return out\n",
    "\n",
    "def plot_pair(group: pd.DataFrame, segments: List[pd.DataFrame], out_dir: str, base_name: str) -> Tuple[str, str]:\n",
    "    # --- 固定配色：速度两条 + 车头时距（虚线，且颜色与速度不同） ---\n",
    "    C_FOLLOWER = 'tab:blue'\n",
    "    C_LEADER   = 'tab:orange'\n",
    "    C_THW      = 'tab:green'\n",
    "\n",
    "    follower_kmh = group['follower_v']  # km/h\n",
    "    leader_kmh   = group['leader_v']    # km/h\n",
    "    t   = group['time_s']\n",
    "    thw = group['time_headway_s']\n",
    "\n",
    "    # 有效性与连续性判定\n",
    "    valid_mask = (group['follower_v'] > 3.6) & (group['headway_distance_m'] <= 100.0)\n",
    "    cont_mask  = group['frame_id'].diff().fillna(1) == 1\n",
    "    contiguous_valid = valid_mask & cont_mask\n",
    "    contiguous_valid.iloc[0] = bool(valid_mask.iloc[0])\n",
    "\n",
    "    spans: List[Tuple[int,int,bool]] = []\n",
    "    start = 0\n",
    "    is_valid = bool(contiguous_valid.iloc[0])\n",
    "    for i in range(1, len(group)):\n",
    "        if bool(contiguous_valid.iloc[i]) != is_valid:\n",
    "            spans.append((start, i-1, is_valid))\n",
    "            start = i\n",
    "            is_valid = bool(contiguous_valid.iloc[i])\n",
    "    spans.append((start, len(group)-1, is_valid))\n",
    "\n",
    "    # 短于 1s 的“有效”片段视为无效高亮\n",
    "    for idx, (s, e, valid) in enumerate(spans):\n",
    "        if valid and (t.iloc[e] - t.iloc[s] < 1.0):\n",
    "            spans[idx] = (s, e, False)\n",
    "\n",
    "    # ===================== Original =====================\n",
    "    original_path = os.path.join(out_dir, f\"{base_name}_original.png\")\n",
    "    fig = plt.figure(figsize=(9,4))\n",
    "    ax1 = plt.gca()\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    # 明确颜色与线型\n",
    "    ax1.plot(t, follower_kmh, label='Follower speed', color=C_FOLLOWER, linewidth=1.2)\n",
    "    ax1.plot(t, leader_kmh,   label='Leader speed',   color=C_LEADER,   linewidth=1.2)\n",
    "    ax2.plot(t, thw,          label='Time headway (s)', color=C_THW, linestyle='--', linewidth=1.2)\n",
    "\n",
    "    ax1.set_xlabel('Time (s)')\n",
    "    ax1.set_ylabel('Speed (km/h)')\n",
    "    ax2.set_ylabel('Time headway (s)')\n",
    "    ax2.tick_params(axis='y')\n",
    "\n",
    "    # 高亮无效时段\n",
    "    for s, e, valid in spans:\n",
    "        if not valid:\n",
    "            # 黄色：仅不连续但数值条件满足；红色：数值条件本身不满足\n",
    "            color = 'yellow' if bool(valid_mask.iloc[s]) else 'red'\n",
    "            ax1.axvspan(t.iloc[s], t.iloc[e], color=color, alpha=0.3)\n",
    "\n",
    "    # 合并双轴图例\n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    by_label = {}\n",
    "    for h, lb in zip(lines1 + lines2, labels1 + labels2):\n",
    "        if lb not in by_label:\n",
    "            by_label[lb] = h\n",
    "    ax1.legend(by_label.values(), by_label.keys(), fontsize=7, loc='best')\n",
    "\n",
    "    plt.title(f\"Original: {base_name}\")\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(original_path, dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "    # ===================== Filtered (only segments) =====================\n",
    "    filtered_path = os.path.join(out_dir, f\"{base_name}_1st_filtered.png\")\n",
    "    fig = plt.figure(figsize=(9,4))\n",
    "    ax1 = plt.gca()\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    segment_boundaries = []\n",
    "    first = True  # 只在第一段打图例标签，其余段避免重复\n",
    "    for seg in segments:\n",
    "        t_seg = seg['time_s']\n",
    "        if t_seg.empty:\n",
    "            continue\n",
    "\n",
    "        # 固定颜色 & 仅第一段带 label\n",
    "        ax1.plot(t_seg, seg['follower_v'],\n",
    "                 color=C_FOLLOWER, linewidth=1.2,\n",
    "                 label='Follower speed' if first else '_nolegend_')\n",
    "        ax1.plot(t_seg, seg['leader_v'],\n",
    "                 color=C_LEADER, linewidth=1.2,\n",
    "                 label='Leader speed' if first else '_nolegend_')\n",
    "        ax2.plot(t_seg, seg['time_headway_s'],\n",
    "                 color=C_THW, linestyle='--', linewidth=1.2,\n",
    "                 label='Time headway (s)' if first else '_nolegend_')\n",
    "\n",
    "        start_t, end_t = t_seg.iloc[0], t_seg.iloc[-1]\n",
    "        segment_boundaries.append((start_t, end_t))\n",
    "\n",
    "        # 端点标记（也用固定色，便于区分）\n",
    "        ax1.scatter([start_t, end_t],\n",
    "                    [seg['follower_v'].iloc[0], seg['follower_v'].iloc[-1]],\n",
    "                    marker='o', s=16, color=C_FOLLOWER)\n",
    "        ax1.scatter([start_t, end_t],\n",
    "                    [seg['leader_v'].iloc[0],  seg['leader_v'].iloc[-1]],\n",
    "                    marker='o', s=16, color=C_LEADER)\n",
    "        ax2.scatter([start_t, end_t],\n",
    "                    [seg['time_headway_s'].iloc[0], seg['time_headway_s'].iloc[-1]],\n",
    "                    marker='o', s=16, color=C_THW)\n",
    "\n",
    "        first = False\n",
    "\n",
    "    ax1.set_xlabel('Time (s)')\n",
    "    ax1.set_ylabel('Speed (km/h)')\n",
    "    ax2.set_ylabel('Time headway (s)')\n",
    "    ax2.tick_params(axis='y')\n",
    "\n",
    "    # 片段边界虚线\n",
    "    for start_t, end_t in segment_boundaries:\n",
    "        ax1.axvline(start_t, linestyle=':', linewidth=0.8)\n",
    "        ax1.axvline(end_t,   linestyle=':', linewidth=0.8)\n",
    "\n",
    "    # 合并双轴图例（此时 guaranteed 有且仅有三条标签）\n",
    "    lines1, labels1 = ax1.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax2.get_legend_handles_labels()\n",
    "    by_label = {}\n",
    "    for h, lb in zip(lines1 + lines2, labels1 + labels2):\n",
    "        if lb not in by_label:\n",
    "            by_label[lb] = h\n",
    "    ax1.legend(by_label.values(), by_label.keys(), fontsize=7, loc='best')\n",
    "\n",
    "    plt.title(f\"Filtered: {base_name}\")\n",
    "    plt.tight_layout()\n",
    "    fig.savefig(filtered_path, dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "    return original_path, filtered_path\n",
    "\n",
    "\n",
    "# ========================= Streaming writers =========================\n",
    "def _append_df_csv(df: pd.DataFrame, csv_path: str) -> None:\n",
    "    \"\"\"Append df to csv with header only if file not exists.\"\"\"\n",
    "    first = not os.path.exists(csv_path)\n",
    "    df.to_csv(csv_path, mode='a', header=first, index=False)\n",
    "\n",
    "def _append_dict_csv(row: dict, csv_path: str) -> None:\n",
    "    \"\"\"Append one dict row to csv efficiently.\"\"\"\n",
    "    first = not os.path.exists(csv_path)\n",
    "    pd.DataFrame([row]).to_csv(csv_path, mode='a', header=first, index=False)\n",
    "\n",
    "# ========================= Per-file processing =========================\n",
    "NEEDED_COLS = [\n",
    "    'part','frame_id','time_s',\n",
    "    'follower_uid','leader_uid',\n",
    "    'headway_distance_m','net_headway_distance_m',\n",
    "    'time_headway_s','net_time_headway_s',\n",
    "    'rel_v_kph','rel_a_mps2',\n",
    "    'TTC_s',\n",
    "    'leader_v','leader_a',\n",
    "    'follower_v','follower_a'\n",
    "]\n",
    "\n",
    "DTYPES_NUMERIC_FLOAT32 = [\n",
    "    'time_s','headway_distance_m','net_headway_distance_m',\n",
    "    'time_headway_s','net_time_headway_s',\n",
    "    'rel_v_kph','rel_a_mps2','TTC_s',\n",
    "    'leader_v','leader_a','follower_v','follower_a'\n",
    "]\n",
    "\n",
    "def process_dataset(file_path: str, output_root: str) -> None:\n",
    "    \"\"\"\n",
    "    Process ONE Excel file (single sheet index 0), stream outputs to CSVs,\n",
    "    and free memory aggressively.\n",
    "    \"\"\"\n",
    "    # Read only needed columns with compact dtypes (saves RAM)\n",
    "    df = pd.read_excel(\n",
    "        file_path, sheet_name=0, usecols=lambda c: c in set(NEEDED_COLS)\n",
    "    )\n",
    "\n",
    "    # Dtypes: compact & consistent\n",
    "    if 'part' in df.columns:\n",
    "        # part 能转小整数\n",
    "        try:\n",
    "            df['part'] = pd.to_numeric(df['part'], errors='coerce').fillna(-1).astype('int16')\n",
    "        except Exception:\n",
    "            df['part'] = df['part'].astype(str)\n",
    "    for col in ['frame_id']:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').astype('Int32').astype('float64')  # keep numeric for diff\n",
    "    for col in DTYPES_NUMERIC_FLOAT32:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce').astype('float32')\n",
    "    for col in ['follower_uid','leader_uid']:\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(str)\n",
    "\n",
    "    lane_name = infer_lane_name(file_path, df)\n",
    "    file_stub = os.path.splitext(os.path.basename(file_path))[0]\n",
    "\n",
    "    parts = sorted(pd.unique(df['part'])) if 'part' in df.columns else [0]\n",
    "\n",
    "    # Process each part independently (lower memory peak)\n",
    "    for part in parts:\n",
    "        part_df = df[df['part'] == part].copy() if 'part' in df.columns else df.copy()\n",
    "        part_df.sort_values(['follower_uid','leader_uid','frame_id'], inplace=True)\n",
    "\n",
    "        # Output dirs include lane + file_stub + part (avoid collisions across files)\n",
    "        part_dir = os.path.join(output_root, f\"{lane_name}_{file_stub}_part{part}\")\n",
    "        filtered_plots_dir  = os.path.join(part_dir, f\"{lane_name}_{file_stub}_part{part}_1st_filtered_plots\")\n",
    "        original_plots_dir  = os.path.join(part_dir, f\"{lane_name}_{file_stub}_part{part}_original_plots\")\n",
    "        os.makedirs(filtered_plots_dir, exist_ok=True)\n",
    "        os.makedirs(original_plots_dir, exist_ok=True)\n",
    "\n",
    "        # Streaming CSV paths\n",
    "        seg_csv_path   = os.path.join(part_dir, f\"{lane_name}_{file_stub}_part{part}_1st_filtered_data.csv\")\n",
    "        summ_csv_path  = os.path.join(part_dir, f\"{lane_name}_{file_stub}_part{part}_1st_segment_summary.csv\")\n",
    "\n",
    "        # Remove old outputs for idempotency (optional)\n",
    "        for p in [seg_csv_path, summ_csv_path]:\n",
    "            if os.path.exists(p):\n",
    "                os.remove(p)\n",
    "\n",
    "        # Group-by pair, but DON'T collect all segments in memory\n",
    "        for (follower, leader), group in part_df.groupby(['follower_uid','leader_uid'], sort=False):\n",
    "            group_sorted = group.sort_values('frame_id').reset_index(drop=True)\n",
    "\n",
    "            segments = find_valid_segments(group_sorted)\n",
    "            if not segments:\n",
    "                del group_sorted\n",
    "                continue\n",
    "\n",
    "            # Write per-segment rows & summary in streaming way\n",
    "            for seg_id, seg in enumerate(segments, start=1):\n",
    "                seg = seg.copy()\n",
    "                seg['segment_id']   = seg_id\n",
    "                seg['part']         = part  # ensure part is kept\n",
    "                # Append this segment's rows\n",
    "                _append_df_csv(seg, seg_csv_path)\n",
    "\n",
    "                # Summary row\n",
    "                stats = compute_segment_statistics(seg)\n",
    "                _append_dict_csv({\n",
    "                    'segment_id': seg_id,\n",
    "                    'part': part,\n",
    "                    'follower_uid': follower,\n",
    "                    'leader_uid': leader,\n",
    "                    **stats\n",
    "                }, summ_csv_path)\n",
    "\n",
    "                # release seg promptly\n",
    "                del seg\n",
    "\n",
    "            # Plot for this pair\n",
    "            base_name = f\"{lane_name}_{file_stub}_part{part}_{follower}_{leader}\"\n",
    "            orig_path, filt_path = plot_pair(group_sorted, segments, original_plots_dir, base_name)\n",
    "            # Move filtered plot into the filtered_plots_dir\n",
    "            os.replace(filt_path, os.path.join(filtered_plots_dir, os.path.basename(filt_path)))\n",
    "\n",
    "            # release group & segments\n",
    "            del group_sorted, segments\n",
    "            gc.collect()\n",
    "\n",
    "        # release part dataframe\n",
    "        del part_df\n",
    "        gc.collect()\n",
    "\n",
    "    # release whole df\n",
    "    del df\n",
    "    gc.collect()\n",
    "\n",
    "# ========================= Multi-file batch =========================\n",
    "def _expand_inputs(paths_or_dirs: Iterable[str], pattern: str, recursive: bool=True) -> List[str]:\n",
    "    \"\"\"\n",
    "    Expand a mixed list of files/dirs into a list of Excel files matching pattern.\n",
    "    - If an item is a file ending with .xlsx, keep it.\n",
    "    - If a dir, glob with pattern inside (recursive optional).\n",
    "    \"\"\"\n",
    "    found = []\n",
    "    for p in paths_or_dirs:\n",
    "        if os.path.isfile(p) and p.lower().endswith('.xlsx'):\n",
    "            found.append(p)\n",
    "        elif os.path.isdir(p):\n",
    "            glob_pat = os.path.join(p, '**', pattern) if recursive else os.path.join(p, pattern)\n",
    "            found.extend(glob.glob(glob_pat, recursive=recursive))\n",
    "        else:\n",
    "            # allow glob expression directly\n",
    "            found.extend(glob.glob(p, recursive=recursive))\n",
    "    # de-dup & sort\n",
    "    found = sorted(list(dict.fromkeys(found)))\n",
    "    return found\n",
    "\n",
    "def process_many(paths_or_dirs: Iterable[str],\n",
    "                 output_root: str,\n",
    "                 pattern: str = '*following_parts*.xlsx',\n",
    "                 recursive: bool = True) -> None:\n",
    "    \"\"\"\n",
    "    Batch process multiple lane files (or directories).\n",
    "    Files are handled SEQUENTIALLY to keep memory usage low.\n",
    "    \"\"\"\n",
    "    files = _expand_inputs(paths_or_dirs, pattern=pattern, recursive=recursive)\n",
    "    if not files:\n",
    "        print(f\"[WARN] No files matched. Inputs={paths_or_dirs}, pattern='{pattern}'\")\n",
    "        return\n",
    "\n",
    "    os.makedirs(output_root, exist_ok=True)\n",
    "    print(f\"[INFO] Found {len(files)} files to process.\")\n",
    "    for i, f in enumerate(files, 1):\n",
    "        print(f\"[{i}/{len(files)}] Processing: {f}\")\n",
    "        try:\n",
    "            process_dataset(f, output_root=output_root)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] Failed on {f}: {e}\")\n",
    "        gc.collect()\n",
    "\n",
    "# ========================= Example: batch call =========================\n",
    "# 你可以传“目录”和/或“文件”混合列表。它会自动找出匹配 pattern 的 Excel。\n",
    "# 比如：\n",
    "#   - 传目录：'/.../step4 Splited car following behavior/'\n",
    "#   - 也可直接传具体文件：'/.../lane2_following_parts.xlsx'\n",
    "#   - 或 glob：'/.../lane*/**/*following_parts*.xlsx'\n",
    "inputs = [\n",
    "    '/Volumes/weishanshan/Geo trax tool results/DJI_0031/step4 Splited car following behavior',\n",
    "    # '/Volumes/weishanshan/Geo trax tool results/DJI_0030/step4 Splited car following behavior/lane1_following_parts.xlsx',\n",
    "    # '/Volumes/weishanshan/Geo trax tool results/DJI_0030/step4 Splited car following behavior/lane2_following_parts.xlsx',\n",
    "]\n",
    "output_root = '/Volumes/weishanshan/Geo trax tool results/DJI_0031/step5 the result of 1st fillter outliers'\n",
    "process_many(inputs, output_root=output_root, pattern='*following_parts*.xlsx', recursive=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7f5fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
